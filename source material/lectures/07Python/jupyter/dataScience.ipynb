{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Computing Services\n",
    "Website: [rcs.bu.edu](http://www.bu.edu/tech/support/research/) <br>\n",
    "Tutorial materials: [http://rcs.bu.edu/examples/python/data_analysis](http://rcs.bu.edu/examples/python/data_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a python package that deals mostly with :\n",
    "- **Series**  (1d homogeneous array)\n",
    "- **DataFrame** (2d labeled heterogeneous array) \n",
    "- **Panel** (general 3d array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas *Series* is one-dimentional labeled array containing data of the same type (integers, strings, floating point numbers, Python objects, etc. ). The axis labels are often referred to as *index*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.269155\n",
      "1    1.147851\n",
      "2   -0.807001\n",
      "3    1.739681\n",
      "4    0.763864\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example of creating Pandas series :\n",
    "s1 = pd.Series( np.random.randn(5) )\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not pass any index, so by default, it assigned the indexes ranging from 0 to len(data)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "# View index values\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.798750\n",
      "b   -0.197451\n",
      "c    1.138628\n",
      "d    0.093001\n",
      "e   -0.779706\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating Pandas series with index:\n",
    "s2 = pd.Series( np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'] )\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View index values\n",
    "print(s2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pi': 3.1415, 'e': 2.71828}\n",
      "e     2.71828\n",
      "pi    3.14150\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a Series from dictionary\n",
    "data = {'pi': 3.1415, 'e': 2.71828}  # dictionary\n",
    "print(data)\n",
    "s3 = pd.Series ( data )\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e      2.71828\n",
      "pi     3.14150\n",
      "tau        NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# reordering the elements\n",
    "s4 = pd.Series ( data, index = ['e', 'pi', 'tau'])\n",
    "print(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAN (non a number) - is used to specify a missing value in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "Name: Ones, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a Pandas Series object from a single number:\n",
    "s5 = pd.Series( 1, index = range(10), name='Ones')\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.269155\n",
      "1    1.147851\n",
      "2   -0.807001\n",
      "3    1.739681\n",
      "4    0.763864\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7396810597034522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many ways to \"slice\" Pandas series (series have zero-based index by default):\n",
    "print(s1)\n",
    "s1[3]  # returns 4th element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[:2] # First 2 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( s1[ [2,1,0]])  # Elements out of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing series using index label (access series like a dictionary)\n",
    "\n",
    "s4['pi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_ALIASES',\n",
       " '_AXIS_IALIASES',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_NAMES',\n",
       " '_AXIS_NUMBERS',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '_AXIS_SLICEMAP',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_numeric_operations',\n",
       " '_add_series_only_operations',\n",
       " '_add_series_or_dataframe_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_doc',\n",
       " '_aggregate',\n",
       " '_aggregate_multiple_funcs',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_allow_index_ops',\n",
       " '_at',\n",
       " '_binop',\n",
       " '_box_item_values',\n",
       " '_builtin_table',\n",
       " '_can_hold_na',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_percentile',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_scalar',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_dict_for_slice',\n",
       " '_construct_axes_dict_from',\n",
       " '_construct_axes_from_arguments',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_create_indexer',\n",
       " '_cython_table',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_expand_axes',\n",
       " '_from_axes',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_numeric_data',\n",
       " '_get_values',\n",
       " '_get_values_tuple',\n",
       " '_get_with',\n",
       " '_gotitem',\n",
       " '_iat',\n",
       " '_iget_item_cache',\n",
       " '_iloc',\n",
       " '_index',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_init_mgr',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_builtin_func',\n",
       " '_is_cached',\n",
       " '_is_cython_func',\n",
       " '_is_datelike_mixed_type',\n",
       " '_is_mixed_type',\n",
       " '_is_numeric_mixed_type',\n",
       " '_is_view',\n",
       " '_ix',\n",
       " '_ixs',\n",
       " '_loc',\n",
       " '_make_cat_accessor',\n",
       " '_make_dt_accessor',\n",
       " '_make_str_accessor',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_needs_reindex_multi',\n",
       " '_obj_with_exclusions',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_axis',\n",
       " '_reindex_indexer',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_repr_data_resource_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_selection_name',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_labels',\n",
       " '_set_name',\n",
       " '_set_subtyp',\n",
       " '_set_values',\n",
       " '_set_with',\n",
       " '_set_with_engine',\n",
       " '_setup_axes',\n",
       " '_shallow_copy',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_try_aggregate_string_function',\n",
       " '_typ',\n",
       " '_unpickle_series_compat',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " '_xs',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_blocks',\n",
       " 'as_matrix',\n",
       " 'asfreq',\n",
       " 'asobject',\n",
       " 'asof',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'autocorr',\n",
       " 'axes',\n",
       " 'base',\n",
       " 'between',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'blocks',\n",
       " 'bool',\n",
       " 'clip',\n",
       " 'clip_lower',\n",
       " 'clip_upper',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compound',\n",
       " 'compress',\n",
       " 'consolidate',\n",
       " 'convert_objects',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'factorize',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_array',\n",
       " 'from_csv',\n",
       " 'ftype',\n",
       " 'ftypes',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'get_dtype_counts',\n",
       " 'get_ftype_counts',\n",
       " 'get_value',\n",
       " 'get_values',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'hasnans',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'imag',\n",
       " 'index',\n",
       " 'interpolate',\n",
       " 'is_copy',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'items',\n",
       " 'itemsize',\n",
       " 'iteritems',\n",
       " 'ix',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'nonzero',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'quantile',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'ravel',\n",
       " 'rdiv',\n",
       " 'real',\n",
       " 'reindex',\n",
       " 'reindex_axis',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'reshape',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'searchsorted',\n",
       " 'select',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_value',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sortlevel',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dense',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_frame',\n",
       " 'to_hdf',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_msgpack',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_sparse',\n",
       " 'to_sql',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'tolist',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tshift',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unique',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'valid',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series can be used as ndarray:\n",
    "print(\"Median:\" , s4.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[s1 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy functions can be used on series as usual:\n",
    "s4[s4 > s4.median()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.764025\n",
       "1    3.151412\n",
       "2    0.446194\n",
       "3    5.695527\n",
       "4    2.146554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector operations:\n",
    "np.exp(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    2.0\n",
       "2    4.0\n",
       "3    6.0\n",
       "4    8.0\n",
       "5    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unlike ndarray Series automatically allign the data based on label:\n",
    "s5 = pd.Series (range(6))\n",
    "print(s5)\n",
    "s5[1:] + s5[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popular Attributes and Methods:\n",
    "\n",
    "|  Attribute/Method | Description |\n",
    "|-----|-----|\n",
    "| dtype | data type of values in series |\n",
    "| empty | True if series is empty |\n",
    "| size | number of elements |\n",
    "| values | Returns values as ndarray |\n",
    "| head() | First n elements |\n",
    "| tail() | Last n elements |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of your choice and explore it\n",
    "# <your code goes here >\n",
    "mys = pd.Series( np.random.randn(21))\n",
    "print(mys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mys.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas *DataFrame* is two-dimensional, size-mutable, heterogeneous tabular data structure with labeled rows and columns ( axes ). Can be thought of a dictionary-like container to store python Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =  pd.DataFrame({ 'Name': pd.Series(['Alice','Bob','Chris']), \n",
    "                  'Age': pd.Series([ 21,25,23]) } )\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column:\n",
    "d['height'] = pd.Series([5.2,6.0,5.6])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file\n",
    "df = pd.read_csv(\"http://rcs.bu.edu/examples/python/data_analysis/Salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display a few first records\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first 10 records\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first 20 records\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the last 5 records\n",
    "# <your code goes here>\n",
    "df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the type of df object\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the type of a column \"salary\"\n",
    "df['salary'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the types of all columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the row labels and the column names\n",
    "df.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of dimensions\n",
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of elements in the Data Frame\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output basic statistics for the numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for all numeric columns\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the standard deviation (std() method) for all numeric columns\n",
    "# <your code goes here>\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average of the columns in the first 50 rows\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Data slicing and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a column by name (method 1)\n",
    "df['sex'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a column name (method 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the basic statistics for the salary column (used describe() method)\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate how many values in the salary column (use count() method)\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data using rank\n",
    "df_rank = df.groupby('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean of all numeric columns for the grouped object\n",
    "df_rank.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean salary for men and women. The following produce Pandas Series (single brackets around salary)\n",
    "df.groupby('sex')['salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use double brackets Pandas will produce a DataFrame\n",
    "df.groupby('sex')[['salary']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group using 2 variables - sex and rank:\n",
    "df.groupby(['rank','sex'], sort=True)[['salary']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by the discipline and find the average salary for each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select observation with the value in the salary column > 120K\n",
    "df_sub = df[ df['salary'] > 120000]\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data for female professors\n",
    "df_w = df[ df['sex'] == 'Female']\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using filtering, find the mean value of the salary for the discipline A\n",
    "df[ df['discipline'] =='A'].mean().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challange:\n",
    "# Extract (filter) only observations with high salary ( > 100K) and find how many female and male professors in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### More on slicing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select column salary\n",
    "df1 = df['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data type of the result\n",
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the first few elements of the output\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select column salary and make the output to be a data frame\n",
    "df2 = df[['salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the type\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a subset of rows (based on their position):\n",
    "# Note 1: The location of the first row is 0\n",
    "# Note 2: The last value in the range is not included\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to select both rows and columns we can use method .loc\n",
    "df.loc[10:20,['rank', 'sex','salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what we get for our df_sub data frame\n",
    "# Method .loc subset the data frame based on the labels:\n",
    "df_sub.loc[10:20,['rank','sex','salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Unlike method .loc, method iloc selects rows (and columns) by poistion:\n",
    "df_sub.iloc[10:20, [0,3,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame by yrs.service and create a new data frame\n",
    "df_sorted = df.sort_values(by = 'service')\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame by yrs.service and overwrite the original dataset\n",
    "df.sort_values(by = 'service', ascending = False, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original order (by sorting using index)\n",
    "df.sort_index(axis=0, ascending = True, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data frame by the salary (in descending order) and display the first few records of the output (head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame using 2 or more columns:\n",
    "df_sorted = df.sort_values(by = ['service', 'salary'], ascending = [True,False])\n",
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a dataset with missing values\n",
    "flights = pd.read_csv(\"http://rcs.bu.edu/examples/python/data_analysis/flights.csv\")\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the rows that have at least one missing value\n",
    "flights[flights.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all the rows where arr_delay value is missing:\n",
    "flights1 = flights[ flights['arr_delay'].notnull( )]\n",
    "flights1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the observations with missing values\n",
    "flights2 = flights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zeros\n",
    "nomiss =flights['dep_delay'].fillna(0)\n",
    "nomiss.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many missing data are in dep_delay and arr_delay columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Common Aggregation Functions:\n",
    "\n",
    "|Function|Description\n",
    "|-------|--------\n",
    "|min   | minimum\n",
    "|max   | maximum\n",
    "|count   | number of non-null observations\n",
    "|sum   | sum of values\n",
    "|mean  | arithmetic mean of values\n",
    "|median | median\n",
    "|mad | mean absolute deviation\n",
    "|mode | mode\n",
    "|prod   | product of values\n",
    "|std  | standard deviation\n",
    "|var | unbiased variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of non-missing values in each column\n",
    "flights.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean value for all the columns in the dataset\n",
    "flights.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute summary statistic per a group':\n",
    "flights.groupby('carrier')['dep_delay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use agg() methods for aggregation:\n",
    "flights[['dep_delay','arr_delay']].agg(['min','mean','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of computing different statistics for different columns\n",
    "flights.agg({'dep_delay':['min','mean',max], 'carrier':['nunique']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Function|Description\n",
    "|-------|--------\n",
    "|min   | minimum\n",
    "|max   | maximum\n",
    "|mean  | arithmetic mean of values\n",
    "|median | median\n",
    "|mad | mean absolute deviation\n",
    "|mode | mode\n",
    "|std  | standard deviation\n",
    "|var | unbiased variance\n",
    "|sem | standard error of the mean\n",
    "|skew| sample skewness\n",
    "|kurt|kurtosis\n",
    "|quantile| value at %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convinient describe() function computes a veriety of statistics\n",
    "flights.dep_delay.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of the maximum or minimum value\n",
    "# if there are multiple values matching idxmin() and idxmax() will return the first match\n",
    "flights['dep_delay'].idxmin()  #minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of records for each different value in a vector\n",
    "flights['carrier'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data using graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show graphs withint Python notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use matplotlib to draw a histogram of a salary data\n",
    "plt.hist(df['salary'],bins=8, normed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use seaborn package to draw a histogram\n",
    "sns.distplot(df['salary']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular matplotlib function to display a barplot\n",
    "df.groupby(['rank'])['salary'].count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use seaborn package to display a barplot\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax = sns.barplot(x='rank',y ='salary', data=df, estimator=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 2 groups:\n",
    "ax = sns.barplot(x='rank',y ='salary', hue='sex', data=df, estimator=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Violinplot\n",
    "sns.violinplot(x = \"salary\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot in seaborn\n",
    "sns.jointplot(x='service', y='salary', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we are interested in linear regression plot for 2 numeric variables we can use regplot\n",
    "sns.regplot(x='service', y='salary', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot\n",
    "sns.boxplot(x='rank',y='salary', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side-by-side box plot\n",
    "sns.boxplot(x='rank',y='salary', data=df, hue='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarm plot\n",
    "sns.swarmplot(x='rank',y='salary', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factorplot\n",
    "sns.factorplot(x='carrier',y='dep_delay', data=flights, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot \n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using seaborn package explore the dependency of arr_delay on dep_delay (scatterplot or regplot) using flights dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statsmodel functions:\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fitted model\n",
    "lm = smf.ols(formula='salary ~ service', data=df).fit()\n",
    "\n",
    "#print model summary\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using scikit-learn:\n",
    "from sklearn import linear_model\n",
    "est = linear_model.LinearRegression(fit_intercept = True)   # create estimator object\n",
    "est.fit(df[['service']], df[['salary']])\n",
    "\n",
    "#print result\n",
    "print(\"Coef:\", est.coef_, \"\\nIntercept:\", est.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear model for arr_delay ~ dep_delay\n",
    "\n",
    "\n",
    "#print model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Student T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scipy package:\n",
    "from scipy import stats\n",
    "df_w = df[ df['sex'] == 'Female']['salary']\n",
    "df_m = df[ df['sex'] == 'Male']['salary']\n",
    "stats.ttest_ind(df_w, df_m)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
