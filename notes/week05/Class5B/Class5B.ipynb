{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling with Pandas II\n",
    "\n",
    "<img src=\"images/pipelines.jpg\" width=50% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "\n",
    "<div align = \"left\"> \n",
    "    <br>\n",
    "    <br>\n",
    "Image by <a href=\"https://pixabay.com/photos/lost-places-factory-old-abandoned-2178884/\">Hands off my tags! Michael Gaida</a> from Pixabay.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this class we will talk more about:\n",
    "\n",
    "- \"Tips and tricks\" for working with `pandas`\n",
    "- Handling Missing Data\n",
    "- Combining Datasets: Concat and Append\n",
    "- Visualizing Data using `seaborn` and `pandas`\n",
    "- Additional Notes you may found helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Always use RELATIVE paths!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/firasm/Sync/Teaching/ubco/2022_23/2022WT1/301/data301_course/notes/week05/Class5B'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chord-fingers1.csv   state-abbrevs.csv    state-population.csv\r\n",
      "chord-fingers2.csv   state-areas.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What if your data is not UTF-8 encoded? \n",
    "*(Hint: You will get a UnicodeDecodeError)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 8: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://nfdp.ccfm.org/download/data/csv/NFD\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Area\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20burned\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20by\u001b[39m\u001b[38;5;132;01m%20c\u001b[39;00m\u001b[38;5;124mause\u001b[39m\u001b[38;5;132;01m%20c\u001b[39;00m\u001b[38;5;124mlass\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20-\u001b[39m\u001b[38;5;132;01m%20E\u001b[39;00m\u001b[38;5;124mN\u001b[39m\u001b[38;5;132;01m%20F\u001b[39;00m\u001b[38;5;124mR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:633\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 8: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "url = \"http://nfdp.ccfm.org/download/data/csv/NFD%20-%20Area%20burned%20by%20cause%20class%20-%20EN%20FR.csv\"\n",
    "\n",
    "dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Demo\n",
    "\n",
    "Now what!?\n",
    "\n",
    "Now we google it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And according to [this stack overflow page](https://stackoverflow.com/a/18172249): we should try:\n",
    "\n",
    "```\n",
    "pd.read_csv(url, encoding='latin')\n",
    "```\n",
    "\n",
    "So let's give it a shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Année</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Juridiction</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Origine</th>\n",
       "      <th>Area (hectares)</th>\n",
       "      <th>Data Qualifier</th>\n",
       "      <th>Superficie (en hectare)</th>\n",
       "      <th>Qualificatifs de données</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Human activity</td>\n",
       "      <td>Activités humaines</td>\n",
       "      <td>2393.8</td>\n",
       "      <td>a</td>\n",
       "      <td>2393.8</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>Foudre</td>\n",
       "      <td>55482.6</td>\n",
       "      <td>a</td>\n",
       "      <td>55482.6</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>a</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>BC</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Colombie-Britannique</td>\n",
       "      <td>Human activity</td>\n",
       "      <td>Activités humaines</td>\n",
       "      <td>40278.3</td>\n",
       "      <td>a</td>\n",
       "      <td>40278.3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>BC</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Colombie-Britannique</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>Foudre</td>\n",
       "      <td>35503.5</td>\n",
       "      <td>a</td>\n",
       "      <td>35503.5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>PC</td>\n",
       "      <td>Parks Canada</td>\n",
       "      <td>Parcs Canada</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>42538.0</td>\n",
       "      <td>e</td>\n",
       "      <td>42538.0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>PE</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Île-du-Prince-Édouard</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>0.1</td>\n",
       "      <td>e</td>\n",
       "      <td>0.1</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>QC</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Québec</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>49748.0</td>\n",
       "      <td>e</td>\n",
       "      <td>49748.0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>SK</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>956084.0</td>\n",
       "      <td>e</td>\n",
       "      <td>956084.0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>YT</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Indéterminée</td>\n",
       "      <td>118126.0</td>\n",
       "      <td>e</td>\n",
       "      <td>118126.0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Année ISO          Jurisdiction            Juridiction  \\\n",
       "0     1990   1990  AB               Alberta                Alberta   \n",
       "1     1990   1990  AB               Alberta                Alberta   \n",
       "2     1990   1990  AB               Alberta                Alberta   \n",
       "3     1990   1990  BC      British Columbia   Colombie-Britannique   \n",
       "4     1990   1990  BC      British Columbia   Colombie-Britannique   \n",
       "...    ...    ...  ..                   ...                    ...   \n",
       "1054  2021   2021  PC          Parks Canada           Parcs Canada   \n",
       "1055  2021   2021  PE  Prince Edward Island  Île-du-Prince-Édouard   \n",
       "1056  2021   2021  QC                Quebec                 Québec   \n",
       "1057  2021   2021  SK          Saskatchewan           Saskatchewan   \n",
       "1058  2021   2021  YT                 Yukon                  Yukon   \n",
       "\n",
       "               Cause             Origine  Area (hectares) Data Qualifier  \\\n",
       "0     Human activity  Activités humaines           2393.8              a   \n",
       "1          Lightning              Foudre          55482.6              a   \n",
       "2        Unspecified        Indéterminée           1008.8              a   \n",
       "3     Human activity  Activités humaines          40278.3              a   \n",
       "4          Lightning              Foudre          35503.5              a   \n",
       "...              ...                 ...              ...            ...   \n",
       "1054     Unspecified        Indéterminée          42538.0              e   \n",
       "1055     Unspecified        Indéterminée              0.1              e   \n",
       "1056     Unspecified        Indéterminée          49748.0              e   \n",
       "1057     Unspecified        Indéterminée         956084.0              e   \n",
       "1058     Unspecified        Indéterminée         118126.0              e   \n",
       "\n",
       "      Superficie (en hectare) Qualificatifs de données  \n",
       "0                      2393.8                        a  \n",
       "1                     55482.6                        a  \n",
       "2                      1008.8                        a  \n",
       "3                     40278.3                        a  \n",
       "4                     35503.5                        a  \n",
       "...                       ...                      ...  \n",
       "1054                  42538.0                        e  \n",
       "1055                      0.1                        e  \n",
       "1056                  49748.0                        e  \n",
       "1057                 956084.0                        e  \n",
       "1058                 118126.0                        e  \n",
       "\n",
       "[1059 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(url, encoding=\"latin\")\n",
    "\n",
    "# Works!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What if your data is not comma-separated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 10 fields in line 7, saw 11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chord1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/chord-fingers1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m chord1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 10 fields in line 7, saw 11\n"
     ]
    }
   ],
   "source": [
    "chord1 = pd.read_csv(\"data/chord-fingers1.csv\")\n",
    "chord1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Demo\n",
    "\n",
    "Now what!?\n",
    "\n",
    "Now we google the error message..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And according to [this stack overflow page](https://stackoverflow.com/a/59429173): we should try:\n",
    "\n",
    "```\n",
    "pd.read_csv('data/chord-fingers1.csv', sep=';')\n",
    "```\n",
    "\n",
    "So let's give it a shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHORD_ROOT</th>\n",
       "      <th>CHORD_TYPE</th>\n",
       "      <th>CHORD_STRUCTURE</th>\n",
       "      <th>FINGER_POSITIONS</th>\n",
       "      <th>NOTE_NAMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHORD_ROOT CHORD_TYPE   CHORD_STRUCTURE FINGER_POSITIONS        NOTE_NAMES\n",
       "0         A#         13  1;3;5;b7;9;11;13      x,1,0,2,3,4  A#,C##,G#,B#,F##\n",
       "1         A#         13  1;3;5;b7;9;11;13      4,x,3,2,1,1  A#,G#,B#,C##,F##\n",
       "2         A#         13  1;3;5;b7;9;11;13      1,x,1,2,3,4  A#,G#,C##,F##,B#\n",
       "3         A#      7(#9)       1;3;5;b7;#9      x,1,0,2,4,3  A#,C##,G#,B##,E#\n",
       "4         A#      7(#9)       1;3;5;b7;#9      2,1,3,3,3,x  A#,C##,G#,B##,E#"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord1 = pd.read_csv(\"data/chord-fingers1.csv\", sep=\";\")\n",
    "chord1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHORD_ROOT</th>\n",
       "      <th>CHORD_TYPE</th>\n",
       "      <th>CHORD_STRUCTURE</th>\n",
       "      <th>FINGER_POSITIONS</th>\n",
       "      <th>NOTE_NAMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>x,4,2,3,1,x</td>\n",
       "      <td>Ab,C,F,Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>x,x,3,2,4,1</td>\n",
       "      <td>Ab,C,F,Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>2,x,1,4,x,x</td>\n",
       "      <td>Ab,F,C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>1,x,x,3,4,x</td>\n",
       "      <td>Ab,C,F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>x,x,1,3,1,4</td>\n",
       "      <td>Ab,Eb,F,C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHORD_ROOT CHORD_TYPE CHORD_STRUCTURE FINGER_POSITIONS NOTE_NAMES\n",
       "0         Ab          6         1;3;5;6      x,4,2,3,1,x  Ab,C,F,Ab\n",
       "1         Ab          6         1;3;5;6      x,x,3,2,4,1  Ab,C,F,Ab\n",
       "2         Ab          6         1;3;5;6      2,x,1,4,x,x     Ab,F,C\n",
       "3         Ab          6         1;3;5;6      1,x,x,3,4,x     Ab,C,F\n",
       "4         Ab          6         1;3;5;6      x,x,1,3,1,4  Ab,Eb,F,C"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load in the second part of the dataset in the same way:\n",
    "\n",
    "chord2 = pd.read_csv(\"data/chord-fingers2.csv\", sep=\";\")\n",
    "chord2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chord1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chord2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chord1) + len(chord2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining DataFrames together\n",
    "\n",
    "We saw that our dataset came in two parts (`chord1` and `chord2`).\n",
    "\n",
    "A common task in data analysis is to merge or combine datasets together.\n",
    "There are several combinations we can do. \n",
    "\n",
    "Let's look at just a basic one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `.concat()`\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) on the `.concat()` function\n",
    "\n",
    "![](https://pandas.pydata.org/docs/_images/merging_append1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHORD_ROOT</th>\n",
       "      <th>CHORD_TYPE</th>\n",
       "      <th>CHORD_STRUCTURE</th>\n",
       "      <th>FINGER_POSITIONS</th>\n",
       "      <th>NOTE_NAMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Ab</td>\n",
       "      <td>m7</td>\n",
       "      <td>1;b3;5;b7</td>\n",
       "      <td>1,3,1,1,1,x</td>\n",
       "      <td>Ab,Eb,Gb,Cb,Eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Ab</td>\n",
       "      <td>dim</td>\n",
       "      <td>1;b3;b5</td>\n",
       "      <td>x,x,4,3,1,2</td>\n",
       "      <td>Ab,Cb,Ebb,Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Ab</td>\n",
       "      <td>dim</td>\n",
       "      <td>1;b3;b5</td>\n",
       "      <td>x,1,2,4,3,x</td>\n",
       "      <td>Ab,Ebb,Ab,Cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>x,x,1,1,1,1</td>\n",
       "      <td>Eb,Ab,C,F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Ab</td>\n",
       "      <td>6</td>\n",
       "      <td>1;3;5;6</td>\n",
       "      <td>1,x,3,2,4,1</td>\n",
       "      <td>Ab,Ab,C,F,Ab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CHORD_ROOT CHORD_TYPE   CHORD_STRUCTURE FINGER_POSITIONS        NOTE_NAMES\n",
       "0           A#         13  1;3;5;b7;9;11;13      x,1,0,2,3,4  A#,C##,G#,B#,F##\n",
       "1           A#         13  1;3;5;b7;9;11;13      4,x,3,2,1,1  A#,G#,B#,C##,F##\n",
       "2           A#         13  1;3;5;b7;9;11;13      1,x,1,2,3,4  A#,G#,C##,F##,B#\n",
       "3           A#      7(#9)       1;3;5;b7;#9      x,1,0,2,4,3  A#,C##,G#,B##,E#\n",
       "4           A#      7(#9)       1;3;5;b7;#9      2,1,3,3,3,x  A#,C##,G#,B##,E#\n",
       "..         ...        ...               ...              ...               ...\n",
       "593         Ab         m7         1;b3;5;b7      1,3,1,1,1,x    Ab,Eb,Gb,Cb,Eb\n",
       "594         Ab        dim           1;b3;b5      x,x,4,3,1,2      Ab,Cb,Ebb,Ab\n",
       "595         Ab        dim           1;b3;b5      x,1,2,4,3,x      Ab,Ebb,Ab,Cb\n",
       "596         Ab          6           1;3;5;6      x,x,1,1,1,1         Eb,Ab,C,F\n",
       "597         Ab          6           1;3;5;6      1,x,3,2,4,1      Ab,Ab,C,F,Ab\n",
       "\n",
       "[598 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chord1['New Column'] ='Firas'\n",
    "chord1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHORD_ROOT</th>\n",
       "      <th>CHORD_TYPE</th>\n",
       "      <th>CHORD_STRUCTURE</th>\n",
       "      <th>FINGER_POSITIONS</th>\n",
       "      <th>NOTE_NAMES</th>\n",
       "      <th>New Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "      <td>Firas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "      <td>Firas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "      <td>Firas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "      <td>Firas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "      <td>Firas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,1,2,3,4,1</td>\n",
       "      <td>G,D,G,C,D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,x,3,4,1,1</td>\n",
       "      <td>G,C,D,G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>2,1,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D,G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,x,2,1,3,4</td>\n",
       "      <td>G,B,E,A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,2,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2632 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHORD_ROOT CHORD_TYPE   CHORD_STRUCTURE FINGER_POSITIONS  \\\n",
       "0            A#         13  1;3;5;b7;9;11;13      x,1,0,2,3,4   \n",
       "1            A#         13  1;3;5;b7;9;11;13      4,x,3,2,1,1   \n",
       "2            A#         13  1;3;5;b7;9;11;13      1,x,1,2,3,4   \n",
       "3            A#      7(#9)       1;3;5;b7;#9      x,1,0,2,4,3   \n",
       "4            A#      7(#9)       1;3;5;b7;#9      2,1,3,3,3,x   \n",
       "...         ...        ...               ...              ...   \n",
       "2029          G       sus4             1;4;5      x,1,2,3,4,1   \n",
       "2030          G       sus4             1;4;5      x,x,3,4,1,1   \n",
       "2031          G        6/9         1;3;5;6;9      2,1,1,1,3,4   \n",
       "2032          G        6/9         1;3;5;6;9      x,x,2,1,3,4   \n",
       "2033          G        6/9         1;3;5;6;9      x,2,1,1,3,4   \n",
       "\n",
       "            NOTE_NAMES New Column  \n",
       "0     A#,C##,G#,B#,F##      Firas  \n",
       "1     A#,G#,B#,C##,F##      Firas  \n",
       "2     A#,G#,C##,F##,B#      Firas  \n",
       "3     A#,C##,G#,B##,E#      Firas  \n",
       "4     A#,C##,G#,B##,E#      Firas  \n",
       "...                ...        ...  \n",
       "2029         G,D,G,C,D        NaN  \n",
       "2030           G,C,D,G        NaN  \n",
       "2031       G,B,E,A,D,G        NaN  \n",
       "2032           G,B,E,A        NaN  \n",
       "2033         G,B,E,A,D        NaN  \n",
       "\n",
       "[2632 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([chord1, chord2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHORD_ROOT</th>\n",
       "      <th>CHORD_TYPE</th>\n",
       "      <th>CHORD_STRUCTURE</th>\n",
       "      <th>FINGER_POSITIONS</th>\n",
       "      <th>NOTE_NAMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,1,2,3,4,1</td>\n",
       "      <td>G,D,G,C,D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,x,3,4,1,1</td>\n",
       "      <td>G,C,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>2,1,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,x,2,1,3,4</td>\n",
       "      <td>G,B,E,A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,2,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2632 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHORD_ROOT CHORD_TYPE   CHORD_STRUCTURE FINGER_POSITIONS  \\\n",
       "0            A#         13  1;3;5;b7;9;11;13      x,1,0,2,3,4   \n",
       "1            A#         13  1;3;5;b7;9;11;13      4,x,3,2,1,1   \n",
       "2            A#         13  1;3;5;b7;9;11;13      1,x,1,2,3,4   \n",
       "3            A#      7(#9)       1;3;5;b7;#9      x,1,0,2,4,3   \n",
       "4            A#      7(#9)       1;3;5;b7;#9      2,1,3,3,3,x   \n",
       "...         ...        ...               ...              ...   \n",
       "2029          G       sus4             1;4;5      x,1,2,3,4,1   \n",
       "2030          G       sus4             1;4;5      x,x,3,4,1,1   \n",
       "2031          G        6/9         1;3;5;6;9      2,1,1,1,3,4   \n",
       "2032          G        6/9         1;3;5;6;9      x,x,2,1,3,4   \n",
       "2033          G        6/9         1;3;5;6;9      x,2,1,1,3,4   \n",
       "\n",
       "            NOTE_NAMES  \n",
       "0     A#,C##,G#,B#,F##  \n",
       "1     A#,G#,B#,C##,F##  \n",
       "2     A#,G#,C##,F##,B#  \n",
       "3     A#,C##,G#,B##,E#  \n",
       "4     A#,C##,G#,B##,E#  \n",
       "...                ...  \n",
       "2029         G,D,G,C,D  \n",
       "2030           G,C,D,G  \n",
       "2031       G,B,E,A,D,G  \n",
       "2032           G,B,E,A  \n",
       "2033         G,B,E,A,D  \n",
       "\n",
       "[2632 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You NEED to save the output of all pandas function, do NOT use the \"inplace\" argument, it will be deprecated soon\n",
    "\n",
    "chords = pd.concat([chord1, chord2])\n",
    "\n",
    "chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `.rename()`\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) on the `.rename()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHORD_ROOT',\n",
       " 'CHORD_TYPE',\n",
       " 'CHORD_STRUCTURE',\n",
       " 'FINGER_POSITIONS',\n",
       " 'NOTE_NAMES']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capitals annoy me!\n",
    "\n",
    "list(chords.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chord</th>\n",
       "      <th>Type</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Finger</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A#</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A#</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chord   Type         Structure       Finger             Notes\n",
       "0    A#     13  1;3;5;b7;9;11;13  x,1,0,2,3,4  A#,C##,G#,B#,F##\n",
       "1    A#     13  1;3;5;b7;9;11;13  4,x,3,2,1,1  A#,G#,B#,C##,F##\n",
       "2    A#     13  1;3;5;b7;9;11;13  1,x,1,2,3,4  A#,G#,C##,F##,B#\n",
       "3    A#  7(#9)       1;3;5;b7;#9  x,1,0,2,4,3  A#,C##,G#,B##,E#\n",
       "4    A#  7(#9)       1;3;5;b7;#9  2,1,3,3,3,x  A#,C##,G#,B##,E#"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords = chords.rename(\n",
    "     \n",
    ")\n",
    "chords.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `.replace()`\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) on the `.replace()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chord</th>\n",
       "      <th>Type</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Finger</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,1,2,3,4,1</td>\n",
       "      <td>G,D,G,C,D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,x,3,4,1,1</td>\n",
       "      <td>G,C,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>2,1,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,x,2,1,3,4</td>\n",
       "      <td>G,B,E,A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,2,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2632 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Chord   Type         Structure       Finger             Notes\n",
       "0     A-sharp     13  1;3;5;b7;9;11;13  x,1,0,2,3,4  A#,C##,G#,B#,F##\n",
       "1     A-sharp     13  1;3;5;b7;9;11;13  4,x,3,2,1,1  A#,G#,B#,C##,F##\n",
       "2     A-sharp     13  1;3;5;b7;9;11;13  1,x,1,2,3,4  A#,G#,C##,F##,B#\n",
       "3     A-sharp  7(#9)       1;3;5;b7;#9  x,1,0,2,4,3  A#,C##,G#,B##,E#\n",
       "4     A-sharp  7(#9)       1;3;5;b7;#9  2,1,3,3,3,x  A#,C##,G#,B##,E#\n",
       "...       ...    ...               ...          ...               ...\n",
       "2029        G   sus4             1;4;5  x,1,2,3,4,1         G,D,G,C,D\n",
       "2030        G   sus4             1;4;5  x,x,3,4,1,1           G,C,D,G\n",
       "2031        G    6/9         1;3;5;6;9  2,1,1,1,3,4       G,B,E,A,D,G\n",
       "2032        G    6/9         1;3;5;6;9  x,x,2,1,3,4           G,B,E,A\n",
       "2033        G    6/9         1;3;5;6;9  x,2,1,1,3,4         G,B,E,A,D\n",
       "\n",
       "[2632 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords_cleaned = chords.replace(\"A#\", \"A-sharp\")\n",
    "chords_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `.drop()`\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) on the `.drop()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chord</th>\n",
       "      <th>Type</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Finger</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>x,1,0,2,3,4</td>\n",
       "      <td>A#,C##,G#,B#,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>4,x,3,2,1,1</td>\n",
       "      <td>A#,G#,B#,C##,F##</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>13</td>\n",
       "      <td>1;3;5;b7;9;11;13</td>\n",
       "      <td>1,x,1,2,3,4</td>\n",
       "      <td>A#,G#,C##,F##,B#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>x,1,0,2,4,3</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-sharp</td>\n",
       "      <td>7(#9)</td>\n",
       "      <td>1;3;5;b7;#9</td>\n",
       "      <td>2,1,3,3,3,x</td>\n",
       "      <td>A#,C##,G#,B##,E#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,1,2,3,4,1</td>\n",
       "      <td>G,D,G,C,D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>G</td>\n",
       "      <td>sus4</td>\n",
       "      <td>1;4;5</td>\n",
       "      <td>x,x,3,4,1,1</td>\n",
       "      <td>G,C,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>2,1,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D,G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,x,2,1,3,4</td>\n",
       "      <td>G,B,E,A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>G</td>\n",
       "      <td>6/9</td>\n",
       "      <td>1;3;5;6;9</td>\n",
       "      <td>x,2,1,1,3,4</td>\n",
       "      <td>G,B,E,A,D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2632 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Chord   Type         Structure       Finger             Notes\n",
       "0     A-sharp     13  1;3;5;b7;9;11;13  x,1,0,2,3,4  A#,C##,G#,B#,F##\n",
       "1     A-sharp     13  1;3;5;b7;9;11;13  4,x,3,2,1,1  A#,G#,B#,C##,F##\n",
       "2     A-sharp     13  1;3;5;b7;9;11;13  1,x,1,2,3,4  A#,G#,C##,F##,B#\n",
       "3     A-sharp  7(#9)       1;3;5;b7;#9  x,1,0,2,4,3  A#,C##,G#,B##,E#\n",
       "4     A-sharp  7(#9)       1;3;5;b7;#9  2,1,3,3,3,x  A#,C##,G#,B##,E#\n",
       "...       ...    ...               ...          ...               ...\n",
       "2029        G   sus4             1;4;5  x,1,2,3,4,1         G,D,G,C,D\n",
       "2030        G   sus4             1;4;5  x,x,3,4,1,1           G,C,D,G\n",
       "2031        G    6/9         1;3;5;6;9  2,1,1,1,3,4       G,B,E,A,D,G\n",
       "2032        G    6/9         1;3;5;6;9  x,x,2,1,3,4           G,B,E,A\n",
       "2033        G    6/9         1;3;5;6;9  x,2,1,1,3,4         G,B,E,A,D\n",
       "\n",
       "[2632 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chords_cleaned = chords_cleaned.drop([\"Notes\", \"New Column\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chord', 'Finger', 'Structure', 'Type']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(chords_cleaned.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chords = chords[sorted(list(chords.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using `.merge()`\n",
    "\n",
    "[User Guide on Merging Dataframes](https://pandas.pydata.org/docs/user_guide/merging.html) on the `.merge()` function\n",
    "\n",
    "<img src =\"images/merge.png\" width = \"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualizing Data using `seaborn` and `pandas`\n",
    "\n",
    "This is a preview of content coming later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# You may need to install seaborn:\n",
    "# Remember the command to install a package `conda install -c conda-forge seaborn`\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y=\"Chord\", data=chords)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Additional Notes on Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"images/PDSH-cover-small.png\">\n",
    "\n",
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous.\n",
    "In particular, many interesting datasets will have some amount of data missing.\n",
    "To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n",
    "In this section, we will discuss some general considerations for missing data, discuss how Pandas chooses to represent it, and demonstrate some built-in Pandas tools for handling missing data in Python.\n",
    "Here and throughout the book, we'll refer to missing data in general as *null*, *NaN*, or *NA* values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Trade-Offs in Missing Data Conventions\n",
    "\n",
    "There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame.\n",
    "Generally, they revolve around one of two strategies: using a *mask* that globally indicates missing values, or choosing a *sentinel value* that indicates a missing entry.\n",
    "\n",
    "In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value.\n",
    "\n",
    "In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with NaN (Not a Number), a special value which is part of the IEEE floating-point specification.\n",
    "\n",
    "None of these approaches is without trade-offs: use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. A sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic. Common special values like NaN are not available for all data types.\n",
    "\n",
    "As in most cases where no universally optimal choice exists, different languages and systems use different conventions.\n",
    "For example, the R language uses reserved bit patterns within each data type as sentinel values indicating missing data, while the SciDB system uses an extra byte attached to every cell which indicates a NA state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing Data in Pandas\n",
    "\n",
    "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
    "\n",
    "Pandas could have followed R's lead in specifying bit patterns for each individual data type to indicate nullness, but this approach turns out to be rather unwieldy.\n",
    "While R contains four basic data types, NumPy supports *far* more than this: for example, while R has a single integer type, NumPy supports *fourteen* basic integer types once you account for available precisions, signedness, and endianness of the encoding.\n",
    "Reserving a specific bit pattern in all available NumPy types would lead to an unwieldy amount of overhead in special-casing various operations for various types, likely even requiring a new fork of the NumPy package. Further, for the smaller data types (such as 8-bit integers), sacrificing a bit to use as a mask will significantly reduce the range of values it can represent.\n",
    "\n",
    "NumPy does have support for masked arrays – that is, arrays that have a separate Boolean mask array attached for marking data as \"good\" or \"bad.\"\n",
    "Pandas could have derived from this, but the overhead in both storage, computation, and code maintenance makes that an unattractive choice.\n",
    "\n",
    "With these constraints in mind, Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point ``NaN`` value, and the Python ``None`` object.\n",
    "This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ``None``: Pythonic missing data\n",
    "\n",
    "The first sentinel value used by Pandas is ``None``, a Python singleton object that is often used for missing data in Python code.\n",
    "Because it is a Python object, ``None`` cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type ``'object'`` (i.e., arrays of Python objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This ``dtype=object`` means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects.\n",
    "While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for dtype in [\"object\", \"int\"]:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The use of Python objects in an array also means that if you perform aggregations like ``sum()`` or ``min()`` across an array with a ``None`` value, you will generally get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vals1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This reflects the fact that addition between an integer and ``None`` is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### ``NaN``: Missing numerical data\n",
    "\n",
    "The other missing data representation, ``NaN`` (acronym for *Not a Number*), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.\n",
    "You should be aware that ``NaN`` is a bit like a data virus–it infects any other object it touches.\n",
    "Regardless of the operation, the result of arithmetic with ``NaN`` will be another ``NaN``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "0 * np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vals2.sum(), vals2.min(), vals2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NumPy does provide some special aggregations that will ignore these missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keep in mind that ``NaN`` is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### NaN and None in Pandas\n",
    "\n",
    "``NaN`` and ``None`` both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present.\n",
    "For example, if we set a value in an integer array to ``np.nan``, it will automatically be upcast to a floating-point type to accommodate the NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = pd.Series(range(2), dtype=int)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x[0] = None\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that in addition to casting the integer array to floating point, Pandas automatically converts the ``None`` to a ``NaN`` value.\n",
    "(Be aware that there is a proposal to add a native integer NA to Pandas in the future; as of this writing, it has not been included).\n",
    "\n",
    "While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and in my experience only rarely causes issues.\n",
    "\n",
    "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
    "\n",
    "|Typeclass     | Conversion When Storing NAs | NA Sentinel Value      |\n",
    "|--------------|-----------------------------|------------------------|\n",
    "| ``floating`` | No change                   | ``np.nan``             |\n",
    "| ``object``   | No change                   | ``None`` or ``np.nan`` |\n",
    "| ``integer``  | Cast to ``float64``         | ``np.nan``             |\n",
    "| ``boolean``  | Cast to ``object``          | ``None`` or ``np.nan`` |\n",
    "\n",
    "Keep in mind that in Pandas, string data is always stored with an ``object`` dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Operating on Null Values\n",
    "\n",
    "As we have seen, Pandas treats ``None`` and ``NaN`` as essentially interchangeable for indicating missing or null values.\n",
    "To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures.\n",
    "They are:\n",
    "\n",
    "- ``isnull()``: Generate a boolean mask indicating missing values\n",
    "- ``notnull()``: Opposite of ``isnull()``\n",
    "- ``dropna()``: Return a filtered version of the data\n",
    "- ``fillna()``: Return a copy of the data with missing values filled or imputed\n",
    "\n",
    "We will conclude this section with a brief exploration and demonstration of these routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Detecting null values\n",
    "Pandas data structures have two useful methods for detecting null data: ``isnull()`` and ``notnull()``.\n",
    "Either one will return a Boolean mask over the data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([1, np.nan, \"hello\", None])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As mentioned in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb), Boolean masks can be used directly as a ``Series`` or ``DataFrame`` index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The ``isnull()`` and ``notnull()`` methods produce similar Boolean results for ``DataFrame``s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dropping null values\n",
    "\n",
    "In addition to the masking used before, there are the convenience methods, ``dropna()``\n",
    "(which removes NA values) and ``fillna()`` (which fills in NA values). For a ``Series``,\n",
    "the result is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a ``DataFrame``, there are more options.\n",
    "Consider the following ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, np.nan, 2], [2, 3, 5], [np.nan, 4, 6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We cannot drop single values from a ``DataFrame``; we can only drop full rows or full columns.\n",
    "Depending on the application, you might want one or the other, so ``dropna()`` gives a number of options for a ``DataFrame``.\n",
    "\n",
    "By default, ``dropna()`` will drop all rows in which *any* null value is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, you can drop NA values along a different axis; ``axis=1`` drops all columns containing a null value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this drops some good data as well; you might rather be interested in dropping rows or columns with *all* NA values, or a majority of NA values.\n",
    "This can be specified through the ``how`` or ``thresh`` parameters, which allow fine control of the number of nulls to allow through.\n",
    "\n",
    "The default is ``how='any'``, such that any row or column (depending on the ``axis`` keyword) containing a null value will be dropped.\n",
    "You can also specify ``how='all'``, which will only drop rows/columns that are *all* null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=\"columns\", how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For finer-grained control, the ``thresh`` parameter lets you specify a minimum number of non-null values for the row/column to be kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=\"rows\", thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here the first and last row have been dropped, because they contain only two non-null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Filling null values\n",
    "\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value.\n",
    "This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values.\n",
    "You could do this in-place using the ``isnull()`` method as a mask, but because it is such a common operation Pandas provides the ``fillna()`` method, which returns a copy of the array with the null values replaced.\n",
    "\n",
    "Consider the following ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list(\"abcde\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can fill NA entries with a single value, such as zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.fillna(0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can specify a forward-fill to propagate the previous value forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# forward-fill\n",
    "data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or we can specify a back-fill to propagate the next values backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# back-fill\n",
    "data.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For ``DataFrame``s, the options are similar, but we can also specify an ``axis`` along which the fills take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.fillna(method=\"ffill\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that if a previous value is not available during a forward fill, the NA value remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Datasets: Concat and Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some of the most interesting studies of data come from combining different data sources.\n",
    "These operations can involve anything from very straightforward concatenation of two different datasets, to more complicated database-style joins and merges that correctly handle any overlaps between the datasets.\n",
    "``Series`` and ``DataFrame``s are built with this type of operation in mind, and Pandas includes functions and methods that make this sort of data wrangling fast and straightforward.\n",
    "\n",
    "Here we'll take a look at simple concatenation of ``Series`` and ``DataFrame``s with the ``pd.concat`` function; later we'll dive into more sophisticated in-memory merges and joins implemented in Pandas.\n",
    "\n",
    "We begin with the standard imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For convenience, we'll define this function which creates a ``DataFrame`` of a particular form that will be useful below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind] for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "\n",
    "# example DataFrame\n",
    "make_df(\"ABC\", range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition, we'll create a quick class that allows us to display multiple ``DataFrame``s side by side. The code makes use of the special ``_repr_html_`` method, which IPython uses to implement its rich object display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return \"\\n\".join(\n",
    "            self.template.format(a, eval(a)._repr_html_()) for a in self.args\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\\n\".join(a + \"\\n\" + repr(eval(a)) for a in self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The use of this will become clearer as we continue our discussion in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recall: Concatenation of NumPy Arrays\n",
    "\n",
    "Concatenation of ``Series`` and ``DataFrame`` objects is very similar to concatenation of Numpy arrays, which can be done via the ``np.concatenate`` function as discussed in [The Basics of NumPy Arrays](02.02-The-Basics-Of-NumPy-Arrays.ipynb).\n",
    "Recall that with it, you can combine the contents of two or more arrays into a single array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "z = [7, 8, 9]\n",
    "np.concatenate([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first argument is a list or tuple of arrays to concatenate.\n",
    "Additionally, it takes an ``axis`` keyword that allows you to specify the axis along which the result will be concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = [[1, 2], [3, 4]]\n",
    "np.concatenate([x, x], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple Concatenation with ``pd.concat``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pandas has a function, ``pd.concat()``, which has a similar syntax to ``np.concatenate`` but contains a number of options that we'll discuss momentarily:\n",
    "\n",
    "```python\n",
    "# Signature in Pandas v0.18\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "```\n",
    "\n",
    "``pd.concat()`` can be used for a simple concatenation of ``Series`` or ``DataFrame`` objects, just as ``np.concatenate()`` can be used for simple concatenations of arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser1 = pd.Series([\"A\", \"B\", \"C\"], index=[1, 2, 3])\n",
    "ser2 = pd.Series([\"D\", \"E\", \"F\"], index=[4, 5, 6])\n",
    "pd.concat([ser1, ser2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It also works to concatenate higher-dimensional objects, such as ``DataFrame``s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df1 = make_df(\"AB\", [1, 2])\n",
    "df2 = make_df(\"AB\", [3, 4])\n",
    "display(\"df1\", \"df2\", \"pd.concat([df1, df2])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By default, the concatenation takes place row-wise within the ``DataFrame`` (i.e., ``axis='rows'``).\n",
    "Like ``np.concatenate``, ``pd.concat`` allows specification of an axis along which concatenation will take place.\n",
    "Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df3 = make_df(\"AB\", [0, 1])\n",
    "df4 = make_df(\"CD\", [0, 1])\n",
    "display(\"df3\", \"df4\", \"pd.concat([df3, df4], axis='col')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We could have equivalently specified ``axis=1``; here we've used the more intuitive ``axis='col'``. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Duplicate indices\n",
    "\n",
    "One important difference between ``np.concatenate`` and ``pd.concat`` is that Pandas concatenation *preserves indices*, even if the result will have duplicate indices!\n",
    "Consider this simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = make_df(\"AB\", [0, 1])\n",
    "y = make_df(\"AB\", [2, 3])\n",
    "y.index = x.index  # make duplicate indices!\n",
    "display(\"x\", \"y\", \"pd.concat([x, y])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice the repeated indices in the result.\n",
    "While this is valid within ``DataFrame``s, the outcome is often undesirable.\n",
    "``pd.concat()`` gives us a few ways to handle it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Catching the repeats as an error\n",
    "\n",
    "If you'd like to simply verify that the indices in the result of ``pd.concat()`` do not overlap, you can specify the ``verify_integrity`` flag.\n",
    "With this set to True, the concatenation will raise an exception if there are duplicate indices.\n",
    "Here is an example, where for clarity we'll catch and print the error message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pd.concat([x, y], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ignoring the index\n",
    "\n",
    "Sometimes the index itself does not matter, and you would prefer it to simply be ignored.\n",
    "This option can be specified using the ``ignore_index`` flag.\n",
    "With this set to true, the concatenation will create a new integer index for the resulting ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display(\"x\", \"y\", \"pd.concat([x, y], ignore_index=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Adding MultiIndex keys\n",
    "\n",
    "Another option is to use the ``keys`` option to specify a label for the data sources; the result will be a hierarchically indexed series containing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display(\"x\", \"y\", \"pd.concat([x, y], keys=['x', 'y'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The result is a multiply indexed ``DataFrame``, and we can use the tools discussed in [Hierarchical Indexing](03.05-Hierarchical-Indexing.ipynb) to transform this data into the representation we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Concatenation with joins\n",
    "\n",
    "In the simple examples we just looked at, we were mainly concatenating ``DataFrame``s with shared column names.\n",
    "In practice, data from different sources might have different sets of column names, and ``pd.concat`` offers several options in this case.\n",
    "Consider the concatenation of the following two ``DataFrame``s, which have some (but not all!) columns in common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df5 = make_df(\"ABC\", [1, 2])\n",
    "df6 = make_df(\"BCD\", [3, 4])\n",
    "display(\"df5\", \"df6\", \"pd.concat([df5, df6])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By default, the entries for which no data is available are filled with NA values.\n",
    "To change this, we can specify one of several options for the ``join`` and ``join_axes`` parameters of the concatenate function.\n",
    "By default, the join is a union of the input columns (``join='outer'``), but we can change this to an intersection of the columns using ``join='inner'``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display(\"df5\", \"df6\", \"pd.concat([df5, df6], join='inner')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another option is to directly specify the index of the remaininig colums using the ``join_axes`` argument, which takes a list of index objects.\n",
    "Here we'll specify that the returned columns should be the same as those of the first input:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "display('df5', 'df6',\n",
    "        \"pd.concat([df5, df6], join_axes=[df5.columns])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The combination of options of the ``pd.concat`` function allows a wide range of possible behaviors when joining two datasets; keep these in mind as you use these tools for your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The ``append()`` method\n",
    "\n",
    "Because direct array concatenation is so common, ``Series`` and ``DataFrame`` objects have an ``append`` method that can accomplish the same thing in fewer keystrokes.\n",
    "For example, rather than calling ``pd.concat([df1, df2])``, you can simply call ``df1.append(df2)``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display(\"df1\", \"df2\", \"df1.append(df2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Keep in mind that unlike the ``append()`` and ``extend()`` methods of Python lists, the ``append()`` method in Pandas does not modify the original object–instead it creates a new object with the combined data.\n",
    "It also is not a very efficient method, because it involves creation of a new index *and* data buffer.\n",
    "Thus, if you plan to do multiple ``append`` operations, it is generally better to build a list of ``DataFrame``s and pass them all at once to the ``concat()`` function.\n",
    "\n",
    "In the next section, we'll look at another more powerful approach to combining data from multiple sources, the database-style merges/joins implemented in ``pd.merge``.\n",
    "For more information on ``concat()``, ``append()``, and related functionality, see the [\"Merge, Join, and Concatenate\" section](http://pandas.pydata.org/pandas-docs/stable/merging.html) of the Pandas documentation."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
