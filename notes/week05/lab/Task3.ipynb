{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: COVID-19 EDA\n",
    "\n",
    "For this task, you'll do some further Data Analysis on a given dataset that can be found [here](https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv).\n",
    "\n",
    "Remember to run the following commands below to import all the necessary packages to run this Task.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "The analysis in this Task is based on [this tutorial](https://www.freecodecamp.org/news/exploratory-data-analysis-with-numpy-pandas-matplotlib-seaborn/) by Aakash NS at FreeCodecamp.\n",
    "You are encouraged to go through the tutorial to get much deeper into the analysis.\n",
    "\n",
    "The data for this project is believed to be from [Our World in Data](https://ourworldindata.org/coronavirus#explore-the-global-situation) after a great deal of processing and cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Importing data\n",
    "\n",
    "Load the dataset from a URL using `pandas`, store the dataframe into a variable called `data`.\n",
    "\n",
    "The URL for the dataset is:\n",
    "\n",
    "> https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv\n",
    "\n",
    "Once you've loaded the dataset, print out the **first 13 rows** of the dataset.\n",
    "\n",
    "**Note, do NOT use the `print()` command.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we are examining a dataset that details COVID-19 infection rates in Italy. And there are some values that don't exist in the dataset (`NaN` values).\n",
    "\n",
    "Many datasets have similar properties, and so we need to do some clean up to do some useful analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Further Analysis\n",
    "\n",
    "Find where the **first non-NaN value** of `new_tests` occurs, then print the next 5 rows after that.\n",
    "\n",
    "**Note, do NOT use the `print()` command.**\n",
    "\n",
    "### Sample Output\n",
    "\n",
    "|     | date       |   new_cases |   new_deaths |   new_tests |\n",
    "|----:|:-----------|------------:|-------------:|------------:|\n",
    "| 111 | 2020-04-20 |        3047 |          433 |        7841 |\n",
    "| 112 | 2020-04-21 |        2256 |          454 |       28095 |\n",
    "| 113 | 2020-04-22 |        2729 |          534 |       44248 |\n",
    "| 114 | 2020-04-23 |        3370 |          437 |       37083 |\n",
    "| 115 | 2020-04-24 |        2646 |          464 |       95273 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've done that, use the `count()` function on the data frame to figure out how many non-NaN values there are in **each** column.\n",
    "\n",
    "### Sample Output\n",
    "\n",
    "Your output should be similar to this, the number have to be exactly the same, but the format of the table can be slightly different.\n",
    "\n",
    "|            |   0 |\n",
    "|:-----------|----:|\n",
    "| date       | 248 |\n",
    "| new_cases  | 248 |\n",
    "| new_deaths | 248 |\n",
    "| new_tests  | 135 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out how many missing values there are is a very important component of an exploratory data analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3: Adding a column\n",
    "\n",
    "Create a new column called `incident_rate` that is calculated by dividing the **`new_cases`** by **`new_tests`**\n",
    "\n",
    "### Sample Output\n",
    "\n",
    "Here is what the output should look like for the beginning of the dataset:\n",
    "\n",
    "|     | date       |   new_cases |   new_deaths |   new_tests |   incident_rate |\n",
    "|----:|:-----------|------------:|-------------:|------------:|----------------:|\n",
    "|   0 | 2019-12-31 |           0 |            0 |         nan |    nan          |\n",
    "|   1 | 2020-01-01 |           0 |            0 |         nan |    nan          |\n",
    "|   2 | 2020-01-02 |           0 |            0 |         nan |    nan          |\n",
    "|   3 | 2020-01-03 |           0 |            0 |         nan |    nan          |\n",
    "|   4 | 2020-01-04 |           0 |            0 |         nan |    nan          |\n",
    "|   5 | 2020-01-05 |           0 |            0 |         nan |    nan          |\n",
    "|   6 | 2020-01-06 |           0 |            0 |         nan |    nan          |\n",
    "|   7 | 2020-01-07 |           0 |            0 |         nan |    nan          |\n",
    "|   8 | 2020-01-08 |           0 |            0 |         nan |    nan          |\n",
    "|   9 | 2020-01-09 |           0 |            0 |         nan |    nan          |\n",
    "\n",
    "And here are a few non-NaN rows so you can make sure you calculated the `incident_rate` correctly:\n",
    "\n",
    "|     | date       | new_cases | new_deaths | new_tests | incident_rate |\n",
    "|----:|:-----------|----------:|-----------:|----------:|--------------:|\n",
    "| 111 | 2020-04-20 |      3047 |        433 |      7841 |      0.388598 |\n",
    "| 112 | 2020-04-21 |      2256 |        454 |     28095 |      0.080299 |\n",
    "| 113 | 2020-04-22 |      2729 |        534 |     44248 |     0.0616751 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new column is used to determine the incidence rate of COVID-19, but let's calculate the **average** value of the column.\n",
    "\n",
    "### Sample Output\n",
    "\n",
    "0.02343722903508291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5: Creating a new dataset\n",
    "\n",
    "Sometimes, the dataset contains rows with data that is not useful for the current analysis.\n",
    "In that case, we should remove rows that only have the information we need, but it's generally not a good idea to delete the data from the CSV.\n",
    "Additionally, we should try to keep a variable around that contains the full dataset in case we need it in the future.\n",
    "\n",
    "For our purposes in this analysis, since we need the **`new_tests`** column, can safely drop any row that has `NaN` values in the **`new_tests`** column.\n",
    "\n",
    "Create a new dataframe called `datafiltered` that **only** has the filtered rows after completing the above step.\n",
    "\n",
    "### Sample Output\n",
    "\n",
    "|     | date       |   new_cases |   new_deaths |   new_tests |   incident_rate |\n",
    "|----:|:-----------|------------:|-------------:|------------:|----------------:|\n",
    "| 111 | 2020-04-20 |        3047 |          433 |        7841 |      0.388598   |\n",
    "| 112 | 2020-04-21 |        2256 |          454 |       28095 |      0.080299   |\n",
    "| 113 | 2020-04-22 |        2729 |          534 |       44248 |      0.0616751  |\n",
    "| 114 | 2020-04-23 |        3370 |          437 |       37083 |      0.0908772  |\n",
    "| 115 | 2020-04-24 |        2646 |          464 |       95273 |      0.0277728  |\n",
    "| 116 | 2020-04-25 |        3021 |          420 |       38676 |      0.0781105  |\n",
    "| 117 | 2020-04-26 |        2357 |          415 |       24113 |      0.0977481  |\n",
    "| 118 | 2020-04-27 |        2324 |          260 |       26678 |      0.087113   |\n",
    "| 119 | 2020-04-28 |        1739 |          333 |       37554 |      0.0463067  |\n",
    "| 120 | 2020-04-29 |        2091 |          382 |       38589 |      0.0541864  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6: Describe\n",
    "\n",
    "Now that you've managed to filter your data, you can start using more complex analysis functions. \n",
    "\n",
    "You've already had experience using the [`df.describe().T`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function in the previous task. \n",
    "\n",
    "Repeat the same analysis you did in the previous task on the new **`data_filtered`** object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution to output `df.describe.T` for numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution to output `df.describe.T` for categorical columns:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Initial Thoughts\n",
    "\n",
    "#### 3.4.1. Use this section to record your observations. \n",
    "\n",
    "Does anything jump out at you as surprising or particularly interesting? Feel free to make additional plots as needed to explore your data set.\n",
    "\n",
    "Where do you think you'll go with exploring this dataset? Feel free to take notes in this section and use it as a scratch pad.\n",
    "\n",
    "Any content in this area will only be marked for effort and completeness.\n",
    "\n",
    "#### # Your observations here:\n",
    "\n",
    "- Obs 1\n",
    "- Obs 2\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7: Exporting data\n",
    "\n",
    "Great job! You've done some analysis and now are ready to further examine the dataset in the next Task!\n",
    "\n",
    "But before we do that, save a new dataset called `datafiltered.csv` to a new .csv file in the data folder in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
